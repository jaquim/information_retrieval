{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from math import sqrt, pow, ceil\n",
    "from collections import Counter, defaultdict\n",
    "from decimal import Decimal\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_relevance = [0,1]\n",
    "cut_off = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Simulate Rankings of Relevance for E and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_docs(docs1, docs2):  \n",
    "  \"\"\"\n",
    "  Take two lists of document relevance scores and generate all possible combinations of overlap\n",
    "  between the two lists.\n",
    "  :param docs1: ranking 1 relevance scores\n",
    "  :param docs2: ranking 2 relevance scores\n",
    "  :return: list of lists of tuples with all possible overlapping schemes\n",
    "  \"\"\"\n",
    "  \n",
    "  # Generate all possible document identifiers for irrelevant documents\n",
    "  zero_ids1 = list(range(docs1.count(0))) \n",
    "  if len(zero_ids1) == 0:\n",
    "    zero_ids2 = [[-1] * docs2.count(0)]  \n",
    "  else:\n",
    "    zero_ids2 = list(itertools.permutations(list(range(6)), docs2.count(0)))\n",
    "    zero_ids2 = sorted([[-1 if x>=docs1.count(0) else x for x in ids] for ids in zero_ids2])\n",
    "    zero_ids2 = list(ids for ids,_ in itertools.groupby(zero_ids2))  \n",
    "  \n",
    "  # Generate all possible document identifiers for relevant documents\n",
    "  one_ids1 = list(range(docs1.count(1))) \n",
    "  if len(one_ids1) == 0:\n",
    "    one_ids2 = [[-1] * docs2.count(1)]\n",
    "  else:\n",
    "    one_ids2 = list(itertools.permutations(list(range(6)), docs2.count(1)))\n",
    "    one_ids2 = sorted([[-1 if x>=docs1.count(1) else x for x in ids] for ids in one_ids2])\n",
    "    one_ids2 = list(ids for ids, _ in itertools.groupby(one_ids2))\n",
    "\n",
    "  # Label the documents of ranking 1\n",
    "  ranking1 = []\n",
    "  zero_count = one_count = 0\n",
    "  for doc in docs1:\n",
    "    if doc == 0:\n",
    "      ranking1.append((doc, zero_ids1[zero_count]))\n",
    "      zero_count += 1\n",
    "    else:\n",
    "      ranking1.append((doc, one_ids1[one_count]))\n",
    "      one_count += 1\n",
    "      \n",
    "  # Label the documents of ranking 2\n",
    "  labelled_rankings = []\n",
    "  for zero_ids in zero_ids2:\n",
    "    for one_ids in one_ids2:\n",
    "      ranking2 = []\n",
    "      zero_count = one_count = 0\n",
    "      for doc in docs2:\n",
    "        if doc == 0:\n",
    "          ranking2.append((doc, zero_ids[zero_count]))\n",
    "          zero_count += 1\n",
    "        else:\n",
    "          ranking2.append((doc, one_ids[one_count]))\n",
    "          one_count += 1        \n",
    "      labelled_rankings.append([ranking1, ranking2])\n",
    "\n",
    "  return labelled_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_e = list(map(list, itertools.product(binary_relevance, repeat=cut_off)))\n",
    "system_p = list(map(list, itertools.product(binary_relevance, repeat=cut_off)))\n",
    "\n",
    "ranking_pairs = [list(ranking) for ranking in list(itertools.product(system_e, system_p))]\n",
    "labelled_rankings = [ranking for docs in ranking_pairs for ranking in identify_docs(docs[0], docs[1])]\n",
    "# labelled_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Expected Reciprocal Rank @ Cut-off (ERR@-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_relevance_to_probability = lambda pos_g, max_g: ((2**pos_g) - 1 ) / (2**max_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ERR(ranking, mapping=mapping_relevance_to_probability, n=cut_off):\n",
    "    p, err = 1, 0\n",
    "  \n",
    "    for r in range(0, n):\n",
    "        R = mapping_relevance_to_probability(ranking[r], 1)\n",
    "        err += (p * (R / (r + 1)))\n",
    "        p *= (1 - R)\n",
    "        \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': ['B', 4, 0], '2': ['A', 3, 0], '3': ['B', 3, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def team_draft_interleaving(ranking_a, ranking_b):\n",
    "    #sorting by relevance:\n",
    "    ranking_a, ranking_b = np.sort(ranking_a)[::-1], np.sort(ranking_b)[::-1]\n",
    "    team_a, team_b = 0, 0\n",
    "    # I_dict has rankings number as keys and triplets of [ str \"Team_Name\", int relevance, int id]\n",
    "    I_dict = {\"1\": [],\"2\": [], \"3\": []} \n",
    "    for iteration in range(3):  # not the same algorithm as in the paper, since there is limit on the size of I\n",
    "        b = False #for breaking\n",
    "        #check to determine which team is drafting\n",
    "        if (team_a < team_b) or ((team_a == team_b) and np.random.randint(2) == 1):\n",
    "            for i, rank in enumerate(ranking_a):\n",
    "                if b == True: #stops unnecessary checks\n",
    "                    break\n",
    "                for document in I_dict.values():\n",
    "                    # the first empty value is taken\n",
    "                    try:\n",
    "                        if document[0] == \"A\" and document[2] == i and document[1] == rank: #last check is for redundancy\n",
    "                            break \n",
    "                    except:\n",
    "                        #assignment \n",
    "                        I_dict[str(iteration+1)] = [\"A\",rank,i]\n",
    "                        b = True\n",
    "                        team_a += 1\n",
    "                        break\n",
    "                        \n",
    "        else:\n",
    "            for i, rank in enumerate(ranking_b):\n",
    "                if b == True: #stops unnecessary checks\n",
    "                    break\n",
    "                for document in I_dict.values():\n",
    "                    # the first empty value is taken\n",
    "                    try: #checking is this document exists already\n",
    "                        if document[0] == \"B\" and document[2] == i and document[1] == rank: #last check is for redundancy\n",
    "                            break \n",
    "                    except:\n",
    "                        #assignment \n",
    "                        I_dict[str(iteration+1)] = [\"B\",rank,i]\n",
    "                        team_b += 1\n",
    "                        b = True\n",
    "                        break\n",
    "                        \n",
    "    return I_dict\n",
    "team_draft_interleaving([1,2,3],[2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': ['B', 2, 0], '2': ['A', 2, 0], '3': ['B', 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(d):\n",
    "    denominator=0\n",
    "    tau=3\n",
    "    length=len(d)\n",
    "    for i in range(length):\n",
    "        denominator+=1/((i+1)**tau)\n",
    "    soft={}\n",
    "    for i in range(length):\n",
    "        soft[i]=(1/((i+1)**tau)) / denominator\n",
    "    return soft\n",
    "\n",
    "def probabilistic_interleaving(ranking_a, ranking_b):\n",
    "    #sorting by relevance:\n",
    "    ranking_a, ranking_b = np.sort(ranking_a)[::-1], np.sort(ranking_b)[::-1]\n",
    "    team_a, team_b = 0, 0\n",
    "    id_a, id_b = np.arange(len(ranking_a)), np.arange(len(ranking_b))\n",
    "    # I_dict has rankings number as keys and triplets of [ str \"Team_Name\", int relevance, int id]\n",
    "    I_dict = {\"1\": [],\"2\": [], \"3\": []} \n",
    "    for iteration in range(3):  # not the same algorithm as in the paper, since there is limit on the size of I\n",
    "        \n",
    "        #check to determine which team is drafting\n",
    "        if (team_a < team_b) or ((team_a == team_b) and np.random.randint(2) == 1):\n",
    "            distribution=softmax(ranking_a)\n",
    "            choice=np.random.choice(list(distribution.keys()), p=list(distribution.values()))\n",
    "            I_dict[str(iteration+1)] = [\"A\",ranking_a[choice],id_a[choice]]\n",
    "            team_a += 1\n",
    "            id_a=np.delete(id_a,choice)\n",
    "            ranking_a=np.delete(ranking_a,choice)\n",
    "                        \n",
    "        else:\n",
    "            distribution=softmax(ranking_b)\n",
    "            choice=np.random.choice(list(distribution.keys()), p=list(distribution.values()))\n",
    "            I_dict[str(iteration+1)] = [\"B\",ranking_b[choice],id_b[choice]]\n",
    "            team_b += 1\n",
    "            id_b=np.delete(id_b,choice)\n",
    "            ranking_b=np.delete(ranking_b,choice)\n",
    "                        \n",
    "    return I_dict\n",
    "probabilistic_interleaving([0,1,2], [0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Simulate User Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionBasedModel:\n",
    "\n",
    "    def __init__(self, stored_gammas=False):\n",
    "        self.gamma = defaultdict(float) if not stored_gammas else stored_gammas\n",
    "        self.alpha = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def train(self, training_file = \"YandexRelPredChallenge.txt\", iterations=10):\n",
    "\n",
    "        # Read data into dataframe\n",
    "        columns = [\"SessionID\", \"TimePassed\", \"TypeOfAction\", \"TargetID\", \"RegionID\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        df = pd.read_csv(training_file, sep='\\t', header=None, names=columns)\n",
    "        print(\"Training with EM...\")\n",
    "\n",
    "        for i in range(iterations):\n",
    "\n",
    "            # Initialise sums and counts\n",
    "            gamma_count = defaultdict(float)\n",
    "            alpha_count = defaultdict(lambda: defaultdict(lambda: 2)) # This can be changed\n",
    "\n",
    "            gamma_sum = defaultdict(float)\n",
    "            alpha_sum = defaultdict(lambda: defaultdict(lambda: 1))\n",
    "\n",
    "            # Iterate sessions\n",
    "            grouped = df.groupby(\"SessionID\")\n",
    "            for session_id, session_df in grouped:\n",
    "\n",
    "                # Extract session clicks\n",
    "                session_clicks = session_df[session_df[\"TypeOfAction\"] == \"C\"][\"TargetID\"].tolist()\n",
    "\n",
    "                # Iterate session queries\n",
    "                query_df = session_df[session_df[\"TypeOfAction\"] == \"Q\"]\n",
    "                for j, (index, row) in enumerate(query_df.iterrows()):\n",
    "\n",
    "                    query_id = row[\"TargetID\"]\n",
    "                    for rank in range(1, 11):  # from rank 1 to 10\n",
    "                        document_id = row[rank]\n",
    "\n",
    "                        # Determine what values should be added to the EM formula sums\n",
    "                        if j == len(query_df) - 1 and document_id in session_clicks:\n",
    "                            gamma_value = alpha_value = 1\n",
    "                        else:\n",
    "                            gamma_value = (self.gamma[rank] * (1 - self.alpha[document_id][query_id])) / \\\n",
    "                                          (1 - self.gamma[rank] * self.alpha[document_id][query_id])\n",
    "                            alpha_value = ((1 - self.gamma[rank]) * self.alpha[document_id][query_id]) / \\\n",
    "                                          (1 - self.gamma[rank] * self.alpha[document_id][query_id])\n",
    "\n",
    "                        gamma_sum[rank] += gamma_value\n",
    "                        alpha_sum[document_id][query_id] += alpha_value\n",
    "\n",
    "                        gamma_count[rank] += 1\n",
    "                        alpha_count[document_id][query_id] += 1\n",
    "\n",
    "            # Update variables\n",
    "            for rank, param in self.gamma.items():\n",
    "                self.gamma[rank] = gamma_sum[rank] / gamma_count[rank]\n",
    "\n",
    "            for document_id, document_params in self.alpha.items():\n",
    "                for query_id, param in document_params.items():\n",
    "                    self.alpha[document_id][query_id] = alpha_sum[document_id][query_id] / alpha_count[document_id][query_id]\n",
    "\n",
    "            print(\"Completed iteration\", i+1)\n",
    "        print(\"Training complete\")\n",
    "\n",
    "    def click_prob(self, epsilon, rank, relevance):\n",
    "        # Calculate the probability of clicking on a document\n",
    "        attract = epsilon if relevance == 0 else 1-epsilon\n",
    "        click_prob = float(self.gamma[rank]) * attract\n",
    "        return click_prob\n",
    "\n",
    "    def click_doc(self, epsilon, rank, relevance):\n",
    "        # Decide whether a document is clicked on\n",
    "        random_number = random.uniform(0, 1)\n",
    "        return True if random_number < self.click_prob(epsilon, rank, relevance) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained gammas for 100 iterations\n",
    "gamma_100iterations = defaultdict(float, {1: 0.3550054654104897,\n",
    "                                          2: 0.13883389876739707,\n",
    "                                          3: 0.10206853135242971,\n",
    "                                          4: 0.08068006030090609,\n",
    "                                          5: 0.060412445013970494,\n",
    "                                          6: 0.050668020280122406,\n",
    "                                          7: 0.04427959483064186,\n",
    "                                          8: 0.04203663197828705,\n",
    "                                          9: 0.038073935779387745,\n",
    "                                          10: 0.039047691274259104})\n",
    "model = PositionBasedModel(stored_gammas=gamma_100iterations)\n",
    "# model.train(iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {1: 0.3550054654104897,\n",
       "             2: 0.13883389876739707,\n",
       "             3: 0.10206853135242971,\n",
       "             4: 0.08068006030090609,\n",
       "             5: 0.060412445013970494,\n",
       "             6: 0.050668020280122406,\n",
       "             7: 0.04427959483064186,\n",
       "             8: 0.04203663197828705,\n",
       "             9: 0.038073935779387745,\n",
       "             10: 0.039047691274259104})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31950491886944077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.click_prob(epsilon=0.1, rank=1, relevance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0039047691274259107"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.click_prob(epsilon=0.1, rank=10, relevance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.click_doc(epsilon=0.1, rank=1, relevance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.click_doc(epsilon=0.1, rank=2, relevance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impressions(p1, p0=0.5, alpha=0.05, beta=0.1, z_alpha=0.05, z_beta=0.1):\n",
    "    \n",
    "    null = z_alpha - (alpha * (sqrt(p0 * (1 - p0))))\n",
    "    alternative = z_beta - (beta * (sqrt(p1 * (1 - p1))))\n",
    "    n = ceil(pow(((null + alternative) / (p1 - p0)), 2))\n",
    "    \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_analysis(interleaving_method, click_model, relevances_e, relevances_p):\n",
    "    wins_e, wins_p = 0, 0\n",
    "    n_simulations = 10 ** 3\n",
    "    \n",
    "    for i in range(n_simulations):\n",
    "        \n",
    "        interleaving = interleaving_method(relevances_e, relevances_p)\n",
    "        generated_list = [(value[0], value[1]) for value in interleaving.values()]\n",
    "        \n",
    "        for rank, (team, relevance) in enumerate(generated_list):\n",
    "            click = click_model.click_doc(epsilon=0.1, rank=rank+1, relevance=relevance)\n",
    "            \n",
    "            if click:\n",
    "                if 'A' in team:\n",
    "                    wins_e += 1\n",
    "                    break\n",
    "                else:\n",
    "                    wins_p += 1\n",
    "                    break\n",
    "        \n",
    "    proportion_e = wins_e / (wins_e + wins_p)    \n",
    "    impressions = compute_impressions(proportion_e)\n",
    "            \n",
    "    return impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_significance(interleaving_method, table, labelled_rankings=labelled_rankings, metric=ERR, click_model=model):\n",
    "    \n",
    "    for ranking in labelled_rankings:\n",
    "        \n",
    "        system_e = ranking[0]\n",
    "        system_p = ranking[1]\n",
    "        \n",
    "        relevances_e = [e[0] for e in system_e]\n",
    "        relevances_p = [p[0] for p in system_p]\n",
    "        \n",
    "        metric_e = metric(relevances_e)\n",
    "        metric_p = metric(relevances_p)\n",
    "        \n",
    "        delta_metric = metric_e - metric_p\n",
    "        \n",
    "        if delta_metric >= 0:\n",
    "            try:\n",
    "                impressions = power_analysis(interleaving_method, click_model, relevances_e, relevances_p)\n",
    "                print(impressions)\n",
    "            except:\n",
    "                continue\n",
    "#             print(delta_metric)\n",
    "            table[delta_metric].append(impressions)\n",
    "    \n",
    "        print(table)\n",
    "            \n",
    "            \n",
    "#     bins = np.linspace(0.05, 0.95 , 10)\n",
    "#     table = pd.DataFrame(table)\n",
    "#     groups = table.groupby(pandas.cut(table['index'], bins))\n",
    "    \n",
    "    \n",
    "#     return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.08333333333333334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.08333333333333331\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.16666666666666669\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5833333333333334\n",
      "0.5833333333333334\n",
      "0.5833333333333334\n",
      "0.5833333333333334\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.41666666666666674\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.33333333333333337\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.25000000000000006\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.08333333333333337\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.625\n",
      "0.625\n",
      "0.625\n",
      "0.625\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.45833333333333337\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.375\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.2916666666666667\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.41666666666666663\n",
      "0.41666666666666663\n",
      "0.41666666666666663\n",
      "0.41666666666666663\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.16666666666666663\n",
      "0.16666666666666663\n",
      "0.16666666666666663\n",
      "0.16666666666666663\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.08333333333333326\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.04166666666666663\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "team_draft_table = defaultdict(lambda: list())\n",
    "probabilistic_table = defaultdict(lambda: list())\n",
    "\n",
    "calculate_significance(team_draft_interleaving, team_draft_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
